{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn_model_selection_module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrTdp2Ah+lRtR5gQNo8JX3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HwangHanJae/ml-definitive-guide-pratice/blob/main/sklearn_model_selection_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "사이킷런의 model_selection 모듈\n",
        "- 학습데이터, 테스트데이터 분리\n",
        "- 교차 검증 분할 및 평가\n",
        "- Estimator의 하이퍼 파라미터 튜닝을 위한 함수, 클래스 제공\n"
      ],
      "metadata": {
        "id": "Up47S2FQLxUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터를 분리하지 않으면 생기는 문제상황\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#데이터 로드\n",
        "iris = load_iris()\n",
        "#모델 객체 생성\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "\n",
        "#학습\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "#예측 \n",
        "\n",
        "pred = dt_clf.predict(train_data)\n",
        "\n",
        "#평가\n",
        "print(\"예측 정확도 : \", accuracy_score(train_label, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01yi0gUFO5BE",
        "outputId": "b2f577d0-a3ee-479c-9b56-ae7995943554"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도 :  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미 학습한 데이터를 기반으로 예측을 했기 때문에 정확도가 1.0 (100%)로 나옴\n",
        "(이미 시험문제와 답을 알고 있는 시험을 봤다고 생각하면 됨)\n"
      ],
      "metadata": {
        "id": "rfaa-Z8OP0aS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_test_split() - 학습데이터, 테스트데이터 분리\n",
        "- test_size : 전체 데이터에서 테스트 데이터 세트의 크기를 얼마로 샘플링 할것인가\n",
        "  - 기본값으로 0.25(25%)가 설정\n",
        "- train_size : 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링 할것인가\n",
        "  - train_size 파라미터는 잘 사용하지 않음 \n",
        "  - 대신 test_size를 사용\n",
        "- shuffle : 데이터를 분리하기 전에 데이터를 미리 섞을지 결정\n",
        "  - 기본값은 True\n",
        "  - 데이터를 분산 시키기에 좀더 효율적\n",
        "- random_state : 난수값"
      ],
      "metadata": {
        "id": "UWDHPQyOOzjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 121\n",
        "#테스트 데이터를 전체의 30% , 학습 데이터를 70%로 분리\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=seed)\n",
        "\n",
        "print(\"X_train 크기 : \", X_train.shape)\n",
        "print(\"y_train 크기 : \", y_train.shape)\n",
        "print(\"X_test 크기 : \", X_test.shape)\n",
        "print(\"y_test 크기 : \", y_test.shape)\n",
        "\n",
        "print(\"학습 데이터의 비율 : \", X_train.shape[0] / iris_data.data.shape[0])\n",
        "print(\"테스트 데이터의 비율 : \", X_test.shape[0] / iris_data.data.shape[0])\n",
        "\n",
        "#분리된 데이터로 학습\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "#예측\n",
        "pred=dt_clf.predict(X_test)\n",
        "\n",
        "#평가\n",
        "\n",
        "print(\"예측 정확도 : \", accuracy_score(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYok4Hc1PyPm",
        "outputId": "787dc6ae-b993-4b32-dd8c-2391ea0d482b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train 크기 :  (105, 4)\n",
            "y_train 크기 :  (105,)\n",
            "X_test 크기 :  (45, 4)\n",
            "y_test 크기 :  (45,)\n",
            "학습 데이터의 비율 :  0.7\n",
            "테스트 데이터의 비율 :  0.3\n",
            "예측 정확도 :  0.9555555555555556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 데이터의 크기는 150개로 각각 분리한 학습데이터는 105개, 테스트데이터는 45개 이다.\n",
        "\n",
        "테스트데이터가 45개로 크지 않아 알고리즘의 정확한 예측 성능을 판단하기에는 어렵다.\n",
        "\n",
        "과적합(Overfitting)의 가능성이 높다.\n",
        "- 과적합 : 모델이 학습데이터에만 과도하게 최적화되어 실제 예측을 위한 데이터에서는 성능이 과도하게 떨어지는 것\n",
        "\n"
      ],
      "metadata": {
        "id": "ufG50iH0SOoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "교차검증\n",
        "\n",
        ": 고정된 학습/테스트 데이터로만 평가를 하다보면 고정된 테스트데이터에만 편향되어 모델이 만들어지는 경우를 개선하기 위하여 사용\n",
        "\n",
        "- 학습데이터, 검증데이터, 테스트데이터로 분리하여 평가\n",
        "1. 분리된 학습/검증데이터로 교차검증을 진행\n",
        "2. 남아있는 테스트데이터로 최종평가를 진행"
      ],
      "metadata": {
        "id": "Fu4P5Wt7Sg4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KFold 교차검증\n",
        "\n",
        ": k개의 폴드된 데이터 세트를 학습과 검증을 위한 데이터 세트로 변경하면서 k번 평가르 수행한뒤 이 k개의 평가를 평균한 결과를 가지고 예측 성능을 평가\n",
        "- K는 일반적으로 5, 10을 사용, 5를 사용한다고 가정\n"
      ],
      "metadata": {
        "id": "JN3Q5BzSUPV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KFold 교차검증\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "#5개의 폴드 세트로 분리하는 KFold 객체와 포드 세트별 정확도를 담을 리스트 객체 생성\n",
        "#n_splits == k == 5\n",
        "kfold = KFold(n_splits = 5)\n",
        "cv_accuracy = []\n",
        "print(\"붖꽃 데이터 세트 크기 : \", features.shape[0])\n",
        "\n",
        "n_iter = 0\n",
        "#KFold 객체의 split()메서드를 호출하면 폴드 별 학습용, 검증용 데이터의 로우 인덱스를 array로 반환\n",
        "for train_index, val_index in kfold.split(features) :\n",
        "  #kfold.split()으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_val = features[train_index], features[val_index]\n",
        "  y_train, y_val = label[train_index], label[val_index]\n",
        "\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_val)\n",
        "  n_iter += 1\n",
        "\n",
        "  #반복시 마다 정확도 측정\n",
        "  accuracy = np.round(accuracy_score(y_val, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  val_size = X_val.shape[0]\n",
        "\n",
        "  print(f\"\\n#{n_iter} 교차검증 정확도 : {accuracy}, 학습 데이터 크기 : {train_size}, 검증 데이터 크기 : {val_size}\")\n",
        "  print(f\"#{n_iter} 검증 데이터 인덱스 : {val_index}\")\n",
        "\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "#개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print(\"\\n## 평균 검증 정확도 : \", np.mean(cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfvvBL05Rwxf",
        "outputId": "dce94380-68aa-4d8c-f74e-d270c77c376b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붖꽃 데이터 세트 크기 :  150\n",
            "\n",
            "#1 교차검증 정확도 : 1.0, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
            "#1 검증 데이터 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차검증 정확도 : 1.0, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
            "#2 검증 데이터 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차검증 정확도 : 0.8667, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
            "#3 검증 데이터 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차검증 정확도 : 0.9333, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
            "#4 검증 데이터 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차검증 정확도 : 0.7333, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
            "#5 검증 데이터 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도 :  0.9066599999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stratified KFold\n",
        "\n",
        ": 불균형한 분포를 가진 label(target) 데이터 집합을 위한 KFold 방식\n",
        "- 불균형한 분포를 가진 label 데이터 집합은 특정 label값이 매우 많거나, 적어서 값의 분포가 한쪽으로 치우치는것을 말합니다.\n",
        "\n",
        "- 교차검증 진행할 때 특정 label집합이 한쪽으로 몰려있는 것을 방지함\n",
        "- 학습/검증 데이터 세트에 각각 올바른 비율로 분배함\n",
        "- split() 메서드를 사용시 학습데이터와 label데이터(학습)도 인자로 넣어줘야함"
      ],
      "metadata": {
        "id": "C6CP51E5Wk_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#불균형한 분포를 가진 label 상황(문제상황)\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "iris_df = pd.DataFrame(data=iris.data, columns = iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "\n",
        "print(iris_df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS0NiHyfbJRA",
        "outputId": "26d60f0d-91ea-4bdb-a2c4-618967445915"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2    50\n",
            "1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "label(0,1,2)값은 50개로 동일"
      ],
      "metadata": {
        "id": "J-km_gImbiwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#불균형한 분포를 가진 label 상황(문제상황)\n",
        "\n",
        "#각 교차검증(KFold)시 생성되는 학습/검증 데이터 값의 분포도 확인\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "for train_index, val_index in kfold.split(iris_df):\n",
        "  n_iter += 1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_val = iris_df['label'].iloc[val_index]\n",
        "  print(f\"## 교차 검증 : {n_iter}\")\n",
        "  print(f\"학습 레이블 데이터 분포 :\\n\", label_train.value_counts())\n",
        "  print(f\"검증 레이블 데이터 분포 :\\n\", label_val.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAFScaQHbhR0",
        "outputId": "5e587f16-ca6d-461a-b01b-29f685ddfad0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증 : 1\n",
            "학습 레이블 데이터 분포 :\n",
            " 2    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 :\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증 : 2\n",
            "학습 레이블 데이터 분포 :\n",
            " 2    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 :\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증 : 3\n",
            "학습 레이블 데이터 분포 :\n",
            " 1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 :\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1,2 레이블이 학습할 때 0 레이블의 경우 전혀 학습을 하지 못함\n",
        "\n",
        "또한 검증 레이블이 0밖에 없으므로 학습 모델은 절대 0을 예측하지 못함"
      ],
      "metadata": {
        "id": "3G2Jhn0qcz5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#StratifiedKFold\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "n_iter = 0\n",
        "for train_index, val_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter += 1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_val = iris_df['label'].iloc[val_index]\n",
        "  print(f\"## 교차 검증 {n_iter}\")\n",
        "  print(f\"학습 레이블 데이터 분포 :\\n\", label_train.value_counts())\n",
        "  print(f\"검증 레이블 데이터 분포 :\\n\", label_val.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haeDNomwclQL",
        "outputId": "dba368e9-501a-4a71-c610-b26a0768646f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증 1\n",
            "학습 레이블 데이터 분포 :\n",
            " 2    34\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 :\n",
            " 1    17\n",
            "0    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증 2\n",
            "학습 레이블 데이터 분포 :\n",
            " 1    34\n",
            "2    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 :\n",
            " 2    17\n",
            "0    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증 3\n",
            "학습 레이블 데이터 분포 :\n",
            " 0    34\n",
            "2    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포 :\n",
            " 2    17\n",
            "1    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습/검증 label 값의 분포도가 동일하게 할당되었음\n",
        "\n"
      ],
      "metadata": {
        "id": "QzzV3wB1d847"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#StratifiedKFold 교차검증\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "#5개의 폴드 세트로 분리하는 KFold 객체와 포드 세트별 정확도를 담을 리스트 객체 생성\n",
        "#n_splits == k == 5\n",
        "skfold = StratifiedKFold(n_splits = 3)\n",
        "cv_accuracy = []\n",
        "print(\"붖꽃 데이터 세트 크기 : \", features.shape[0])\n",
        "\n",
        "n_iter = 0\n",
        "#KFold 객체의 split()메서드를 호출하면 폴드 별 학습용, 검증용 데이터의 로우 인덱스를 array로 반환\n",
        "for train_index, val_index in skfold.split(features, label) :\n",
        "  #kfold.split()으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_val = features[train_index], features[val_index]\n",
        "  y_train, y_val = label[train_index], label[val_index]\n",
        "\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_val)\n",
        "  n_iter += 1\n",
        "\n",
        "  #반복시 마다 정확도 측정\n",
        "  accuracy = np.round(accuracy_score(y_val, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  val_size = X_val.shape[0]\n",
        "\n",
        "  print(f\"\\n#{n_iter} 교차검증 정확도 : {accuracy}, 학습 데이터 크기 : {train_size}, 검증 데이터 크기 : {val_size}\")\n",
        "  print(f\"#{n_iter} 검증 데이터 인덱스 : {val_index}\")\n",
        "\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "#개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print(\"\\n## 평균 검증 정확도 : \", np.mean(cv_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGDBTfrVd3gw",
        "outputId": "34953656-63f3-4611-f54c-aaaa8f3927fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붖꽃 데이터 세트 크기 :  150\n",
            "\n",
            "#1 교차검증 정확도 : 0.98, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
            "#1 검증 데이터 인덱스 : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "#2 교차검증 정확도 : 0.94, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
            "#2 검증 데이터 인덱스 : [ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "#3 교차검증 정확도 : 1.0, 학습 데이터 크기 : 100, 검증 데이터 크기 : 50\n",
            "#3 검증 데이터 인덱스 : [ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도 :  0.9733333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross_val_score()\n",
        ": 교차 검증을 좀더 편리하게 수행할 수 있는 API\n",
        "- 위의 일련의 과정들을 한번에 수행해줌\n",
        "  위의 과정들 :\n",
        "    1. 폴드 세트를 설정함\n",
        "    2. for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스를 추출함\n",
        "    3. 반복적으로 학습과 예측을 수행하고 예측 성능을 반환\n",
        "- 파라미터\n",
        "  - estimator : 분류 알고리즘 클래스(Classifier), 회귀 알고리즘 클래스(Regressor)\n",
        "  - X : 피처 데이터 세트\n",
        "  - y : 레이블 데이터 세트\n",
        "  - scoring : 예측 성능 평가 지표\n",
        "  - cv : 교차 검증 폴드 수\n",
        "  - return 값 : scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환\n",
        "- 분류 알고리즘 입력시 StratifiedKFold 분할\n",
        "- 회귀 알고리즘 입력시 KFold로 분할\n",
        "  - 회귀 알고리즘 경우는 특정 수치(값)으로 예측하기 때문에 StraitifedKFold가 필요하지 않음\n"
      ],
      "metadata": {
        "id": "iViHHVRVfQjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cross_val_score()\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data= iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "#성능지표(scoring)은 accurcay(정확도), 교차 검증 세트는 3개\n",
        "\n",
        "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
        "print(\"교차 검증별 정확도 : \", np.round(scores, 4))\n",
        "print(\"평균 검증 정확도 : \", np.round(np.mean(scores),4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnxeDvdwfCZc",
        "outputId": "229ca808-1d1d-4fde-f7f0-e3c6267fb5f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
            "평균 검증 정확도 :  0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross_validate()는 여러개의 평가지표를 반환 할수 있음 또한 학습 데이터에 대한 성능 평가 지표와 수행 시간도 함께 제공"
      ],
      "metadata": {
        "id": "M-PgI_qLhhNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EbBGwnhjhIMy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}